# -*- coding: utf-8 -*-
"""Part of Speech tagging.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16V6JPjKyr75P0VQZUkWnLZAb1StUPKt6

#  Part of Speech tagging

POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. Some of the parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.

Algortihm

Step 1:Start

Step2:Import the required header files
    import nltk 
        NLTK is a set of libraries for Natural Language Processing. It is a platform for building Python programs to process natural language
    from nltk.corpus import state_union
        The NLTK corpus is a massive dump of all kinds of natural language data sets.
    from nltk.tokenize import PunktSentenceTokenizer
        It is a new sentence tokenizer. This tokenizer is capable of unsupervised machine learning, so you can actually train it on any body of text that you use. 
 
Step 3:  create our training and testing data
    One is a State of the Union address from 2005, and the other is from 2006 from past President George W. Bush.
    train_text = state_union.raw("2005-GWBush.txt")
    sample_text = state_union.raw("2006-GWBush.txt")

Step 4:  train the Punkt tokenizer
    custom_sent_tokenizer = PunktSentenceTokenizer(train_text)
    
Step 5: Creating a function that will run through and tag all of the parts of speech per sentence .
   
   
   def process_content():
    try:
        for i in tokenized[:5]:
            words = nltk.word_tokenize(i)
            tagged = nltk.pos_tag(words)
            print(tagged)

    except Exception as e:
        print(str(e))


process_content()

Step 6:Stop

import nltk
from nltk.corpus import state_union
from nltk.tokenize import PunktSentenceTokenizer
nltk.download('state_union')

train_text = state_union.raw("2005-GWBush.txt")
sample_text = state_union.raw("2006-GWBush.txt")
"""

custom_sent_tokenizer = PunktSentenceTokenizer(train_text)

tokenized = custom_sent_tokenizer.tokenize(sample_text)

def process_content():
    try:
        for i in tokenized[:5]:
            words = nltk.word_tokenize(i)
            tagged = nltk.pos_tag(words)
            print(tagged)

    except Exception as e:
        print(str(e))


process_content()





